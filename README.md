# Toxicity-Finder
### Toxicity Flagging API built on top of an LSTM model using Flask

<br>
The REST API serves an output when given a string of text as shown in the screenshot below:
<br> <br>

<img width="1440" alt="Screen Shot 2021-06-15 at 5 18 55 PM" src="https://user-images.githubusercontent.com/53478586/122047450-cc1ffb00-cdfd-11eb-8506-b7515485ab82.png">


------------------------------


A landing page for the API was built and a demo was created in order to show a use-case of the same. 

https://user-images.githubusercontent.com/53478586/122047241-85320580-cdfd-11eb-968a-0cc9cfab2d65.mov

### The web-app is yet to be hosted.



